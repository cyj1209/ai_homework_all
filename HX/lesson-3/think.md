# 什么是监督学习，无监督学习，半监督学习?
    -监督式学习（Supervised learning），是机器学习中的一个方法，可以由标记好的训练集中学到或建立一个模式（函数 / learning model），并依此模式推测新的实例。监督学习要求我们的样本都是具有标签的。
    -无监督学习是一类用于在数据中寻找模式的机器学习技术。无监督学习算法使用的输入数据都是没有标注过的，这意味着样本只给出了特征集合而没有给出相应的标签。在无监督学习中，算法本身将发掘数据中有趣的结构。
    -半监督学习（Semi-Supervised learning），介于无监督学习和监督学习之间。常半监督学习的任务与监督学习一致，即任务中包含有明确的目标（如分类），采用的数据既包括有标签的数据，也包括无标签的数据。但是通常只有少量的数据有标签。


# K-means中的k值如何选取？
    - 手肘法 随着聚类数k的增大，样本划分会更加精细，每个簇的聚合程度会逐渐提高，那么误差平方和SSE自然会逐渐变小。并且，当k小于真实聚类数时，由于k的增大会大幅增加每个簇的聚合程度，故SSE的下降幅度会很大，而当k到达真实聚类数时，再增加k所得到的聚合程度回报会迅速变小，所以SSE的下降幅度会骤减，然后随着k值的继续增大而趋于平缓，也就是说SSE和k的关系图是一个手肘的形状，而这个肘部对应的k值就是数据的真实聚类数。
    最好的方法就是画出k-SSE 的图像，然后就可以直观的看出来k选多少会比价合适。

# 随机森林采用了bagging集成学习，bagging指的是什么？
    -Bagging是Bootstrap aggregating的缩写即引导聚集算法。Bagging的思想很简单，即从原来的数据集中放回的取出数据，同时保持数据集的规模不变。用新的数据集训练弱学习器。重复上述过程多次，取平均值或者采用投票机制。
    
# 表征学习和半监督学习的区别是什么？
    -表征学习是一种将原始数据转换成为能够被机器学习有效开发的一种技术的集合。表征学习允许计算机学习使用特征的同时，也学习如何提取特征：学习如何学习。在机器学习任务中，输入数据例如图片、视频、语言文字、声音等都是高维且冗余复杂，传统的手动提取特征已变得不切合实际，所以需要借助于优秀的特征学习技术。
    -半监督学习详见问题一
    -区别是表征学习的目标不是通过学习原始数据预测某个观察结果，而是学习数据的底层结构（underlying structure），从而可以分析出原始数据的其它特性